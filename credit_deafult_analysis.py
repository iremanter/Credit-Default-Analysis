# -*- coding: utf-8 -*-
"""PAMLP_Final_Credit_Deafult.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dm-Uq6uGnyQtxmk1g08xzIyxfTLubM8E
"""

import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

df = pd.read_csv('Loan_default.csv')

df.head()

df.info()

df.describe().transpose()

df.dtypes

df.isnull().sum()

df.isna().sum()

df.duplicated().sum()

df.drop(columns=['LoanID'], inplace=True)

print(df['Default'].isnull().sum())

df = df.dropna(subset=['Default'])

print(df['Default'].isnull().sum())

categorical_cols = [col for col in df.columns if df[col].dtypes == 'object']

numerical_cols = [col for col in df.columns if df[col].dtypes != 'object']

print(categorical_cols)

print(numerical_cols)

for col in categorical_cols:
      print(df[col].value_counts())

default_education = df.groupby('Education')['Default'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(data=default_education, x='Education', y='Default')
plt.title('Default by Education')
plt.xlabel('Education')
plt.ylabel('Default')
plt.show()
print(default_education)

default_emp_type = df.groupby('EmploymentType')['Default'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(data=default_emp_type, x='EmploymentType', y='Default')
plt.title('Default by Employment Type')
plt.xlabel('EmploymentType')
plt.ylabel('Default')
plt.show()
print(default_emp_type)

default_mar_stat = df.groupby('MaritalStatus')['Default'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(data=default_mar_stat, x='MaritalStatus', y='Default')
plt.title('Default by Martial Status')
plt.xlabel('MaritalStatus')
plt.ylabel('Default')
plt.show()
print(default_mar_stat)

default_has_dept = df.groupby('HasDependents')['Default'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(data=default_has_dept, x='HasDependents', y='Default')
plt.title('Default by Having Dependents')
plt.xlabel('HasDependents')
plt.ylabel('Default')
plt.show();
print(default_has_dept)

default_loan_pur= df.groupby('LoanPurpose')['Default'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(data=default_loan_pur, x='LoanPurpose', y='Default')
plt.title('Default by Loan Purpose')
plt.xlabel('LoanPurpose')
plt.ylabel('Default')
plt.show();
print(default_loan_pur)

default_has_cosign = df.groupby('HasCoSigner')['Default'].sum().reset_index()
plt.figure(figsize=(10, 6))
sns.barplot(data=default_has_cosign, x='HasCoSigner', y='Default')
plt.title('Default by Having Cosigner')
plt.xlabel('Education')
plt.ylabel('Default')
plt.show()
print(default_has_cosign)

# Plot histogram for Income
plt.figure(figsize=(10, 6))
plt.hist(df['Income'], bins=100)
plt.xlabel('Income')
plt.ylabel('Frequency')
plt.title('Histogram of Income')
plt.show()

# Plot histogram for LoanAmount
plt.figure(figsize=(10, 6))
plt.hist(df['LoanAmount'], bins=100)
plt.xlabel('LoanAmount')
plt.ylabel('Frequency')
plt.title('Histogram of Loan Amount')
plt.show()

# Plot histogram for CreditScore
plt.figure(figsize=(10, 6))
plt.hist(df['CreditScore'], bins=100)
plt.xlabel('CreditScore')
plt.ylabel('Frequency')
plt.title('Histogram of Credit Score')
plt.show()

# Plot histogram for Age
plt.figure(figsize=(10, 6))
plt.hist(df['Age'], bins=30)
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Histogram of Age')
plt.show()

import matplotlib.pyplot as plt

for col in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(4, 4))
    plt.boxplot(df[col], vert=False)
    plt.title(f'Boxplot of {col}')
    plt.show()

correlation_matrix = df[numerical_cols].corr()

# Display the correlation matrix
print("\nCorrelation Matrix:")
print(correlation_matrix)

correlation_matrix['Default']

heatmapvariables = pd.DataFrame(df[['Income', 'LoanAmount', 'MonthsEmployed','Default']])

dataplot = sns.heatmap(heatmapvariables.corr())
plt.show()

dataplot = sns.heatmap(correlation_matrix)
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(df[['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'InterestRate', 'LoanTerm',
                'NumCreditLines' ,'DTIRatio',"Default"]].corr(), cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot=True, vmax = 0.6)
plt.title('Correlation Matrix')
plt.show()

encode_cols=['Education','EmploymentType','MaritalStatus']
df_encoded = pd.get_dummies(df, columns=encode_cols)
print(df_encoded)

from sklearn.preprocessing import OneHotEncoder
ohe_columns = ['Education','EmploymentType', 'MaritalStatus']
ohe = OneHotEncoder(drop='first', sparse=False)

encoded_columns = ohe.fit_transform(df[ohe_columns])

df['LoanToIncomeRatio'] = df['LoanAmount']/df['Income']
df['FinancialRiskScore'] = df['CreditScore'] - df['LoanToIncomeRatio'] + (df['MonthsEmployed']/12)

new_var_corr = pd.DataFrame(df[['LoanToIncomeRatio', 'FinancialRiskScore','Default']])

new_var_corr.corr()

feature_names = ohe.get_feature_names_out(ohe_columns)

encoded_df = pd.DataFrame(encoded_columns, columns=feature_names)
df_encoded = pd.concat([df.drop(columns=ohe_columns), encoded_df], axis=1)
print(df_encoded)

education_map = {"High School":0,"Bachelor's": 1, "Master's": 2,"PhD":3}
employment_map = {"Unemployed":0,"Part-time":1,"Full-time": 2, "Self-employed": 3}
marital_map = {'Single': 0, 'Married': 1, 'Divorced': 2}

# Apply mapping to create numeric columns
df['Education_Int'] = df['Education'].map(education_map)
df['EmploymentType_Int'] = df['EmploymentType'].map(employment_map)
df['MaritalStatus_Int'] = df['MaritalStatus'].map(marital_map)

print(df)

df['HasCoSigner'].unique()

mortgage_map = {"No":0,"Yes": 1}
dependents_map = {"No":0,"Yes": 1}
loan_map = {'Other': 0, 'Auto': 1, 'Business': 2,'Home': 3, 'Education': 4}
cosigner_map = {"No":0,"Yes": 1}

# Apply mapping to create numeric columns
df['HasMortgage_Int'] = df['HasMortgage'].map(mortgage_map)
df['HasDependents_Int'] = df['HasDependents'].map(dependents_map)
df['LoanPurpose_Int'] = df['LoanPurpose'].map(loan_map)
df['HasCoSigner_Int'] = df['HasCoSigner'].map(cosigner_map)

print(df)

categorical_corr_2= pd.DataFrame(df[['HasMortgage_Int','HasDependents_Int','LoanPurpose_Int','HasCoSigner_Int','Default']])
dataplot = sns.heatmap(categorical_corr_2.corr())
plt.show()

categorical_corr_2.corr()

categorical_corr= pd.DataFrame(df[['Education_Int','EmploymentType_Int','MaritalStatus_Int','Default']])
dataplot = sns.heatmap(categorical_corr.corr())
plt.show()

categorical_corr.corr()

# Plot histogram for EmploymentType_Int
plt.figure(figsize=(10, 6))
plt.hist(df['MaritalStatus_Int'], bins=10)
plt.xlabel('MaritalStatus_Int')
plt.ylabel('Frequency')
plt.title('Histogram of MaritalStatus_Int')
plt.show()

# Plot histogram with 20 bins using plotly.express
fig = px.histogram(df, x='MonthsEmployed', nbins=20, title='Distribution of Employment Months')

# Update layout for titles and labels
fig.update_layout(
    xaxis_title='Employment Months',
    yaxis_title='Frequency',
    width=1000,
    height=600
)

fig.update_traces(marker=dict(line=dict(color='black', width=1)))
fig.show()

heatmapvariables2 = pd.DataFrame(df[['Education_Int', 'EmploymentType_Int', 'MaritalStatus_Int','Default']])
dataplot = sns.heatmap(correlation_matrix)
plt.show()

plt.figure(figsize=(10, 8))
sns.heatmap(df[['Education_Int', 'EmploymentType_Int', 'MaritalStatus_Int','Default']].corr(), cmap = plt.cm.RdYlBu_r, vmin = -0.25, annot=True, vmax = 0.6)
plt.title('Correlation Matrix')
plt.show()

level_counts=df.LoanPurpose.value_counts()
fig=px.pie(values=level_counts.values,
          names=level_counts.index,
          title= 'Loan Purpose'
          )
fig.show()

df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

X = df_encoded.drop(columns=['Default'])
y = df_encoded['Default']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the feature variables
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

plt.figure(figsize=(12, 8))
sns.heatmap(df_encoded.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

sns.pairplot(df, hue='Default', vars=['Age', 'Income', 'LoanAmount', 'CreditScore'])
plt.show()

sns.countplot(x='Default', data=df)
plt.title('Distribution of Default')
plt.show()

plt.figure(figsize=(14, 10))
sns.boxplot(data=df[['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']])
plt.title('Boxplot for Numerical Variables')
plt.xticks(rotation=45)
plt.show()

df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

X = df_encoded.drop(columns=['Default'])
y = df_encoded['Default']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#Logistic Regression
logreg = LogisticRegression(random_state=42)
logreg.fit(X_train_scaled, y_train)
y_pred_logreg = logreg.predict(X_test_scaled)

#Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

#Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

# Evaluation metrics for Logistic Regression
print("Logistic Regression:")
print("Accuracy:", accuracy_score(y_test, y_pred_logreg))
print("Precision:", precision_score(y_test, y_pred_logreg))
print("Recall:", recall_score(y_test, y_pred_logreg))
print("F1 Score:", f1_score(y_test, y_pred_logreg))
print(classification_report(y_test, y_pred_logreg))

# Evaluation metrics for Random Forest
print("Random Forest:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf))
print("Recall:", recall_score(y_test, y_pred_rf))
print("F1 Score:", f1_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

# Evaluation metrics for Decision Tree
print("Decision Tree:")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("Precision:", precision_score(y_test, y_pred_dt))
print("Recall:", recall_score(y_test, y_pred_dt))
print("F1 Score:", f1_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Confusion Matrix for Logistic Regression
cm_logreg = confusion_matrix(y_test, y_pred_logreg)
disp_logreg = ConfusionMatrixDisplay(confusion_matrix=cm_logreg, display_labels=logreg.classes_)
disp_logreg.plot()
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

# Confusion Matrix for Random Forest
cm_rf = confusion_matrix(y_test, y_pred_rf)
disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf.classes_)
disp_rf.plot()
plt.title("Confusion Matrix - Random Forest")
plt.show()

# Confusion Matrix for Decision Tree
cm_dt = confusion_matrix(y_test, y_pred_dt)
disp_dt = ConfusionMatrixDisplay(confusion_matrix=cm_dt, display_labels=dt.classes_)
disp_dt.plot()
plt.title("Confusion Matrix - Decision Tree")
plt.show()

from sklearn.metrics import roc_curve, auc

# ROC Curve for Logistic Regression
fpr_logreg, tpr_logreg, _ = roc_curve(y_test, logreg.predict_proba(X_test_scaled)[:, 1])
roc_auc_logreg = auc(fpr_logreg, tpr_logreg)

# ROC Curve for Random Forest
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf.predict_proba(X_test_scaled)[:, 1])
roc_auc_rf = auc(fpr_rf, tpr_rf)

# ROC Curve for Decision Tree
fpr_dt, tpr_dt, _ = roc_curve(y_test, dt.predict_proba(X_test_scaled)[:, 1])
roc_auc_dt = auc(fpr_dt, tpr_dt)

# Plot ROC Curve
plt.figure()
plt.plot(fpr_logreg, tpr_logreg, color='blue', lw=2, label='Logistic Regression (area = %0.2f)' % roc_auc_logreg)
plt.plot(fpr_rf, tpr_rf, color='green', lw=2, label='Random Forest (area = %0.2f)' % roc_auc_rf)
plt.plot(fpr_dt, tpr_dt, color='red', lw=2, label='Decision Tree (area = %0.2f)' % roc_auc_dt)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

from sklearn.metrics import precision_recall_curve, average_precision_score

# Precision-Recall Curve for Logistic Regression
precision_logreg, recall_logreg, _ = precision_recall_curve(y_test, logreg.predict_proba(X_test_scaled)[:, 1])
average_precision_logreg = average_precision_score(y_test, logreg.predict_proba(X_test_scaled)[:, 1])

# Precision-Recall Curve for Random Forest
precision_rf, recall_rf, _ = precision_recall_curve(y_test, rf.predict_proba(X_test_scaled)[:, 1])
average_precision_rf = average_precision_score(y_test, rf.predict_proba(X_test_scaled)[:, 1])

# Precision-Recall Curve for Decision Tree
precision_dt, recall_dt, _ = precision_recall_curve(y_test, dt.predict_proba(X_test_scaled)[:, 1])
average_precision_dt = average_precision_score(y_test, dt.predict_proba(X_test_scaled)[:, 1])

# Plot Precision-Recall Curve
plt.figure()
plt.plot(recall_logreg, precision_logreg, color='blue', lw=2, label='Logistic Regression (AP = %0.2f)' % average_precision_logreg)
plt.plot(recall_rf, precision_rf, color='green', lw=2, label='Random Forest (AP = %0.2f)' % average_precision_rf)
plt.plot(recall_dt, precision_dt, color='red', lw=2, label='Decision Tree (AP = %0.2f)' % average_precision_dt)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")
plt.show()